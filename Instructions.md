# ðŸ§© What Is This Project Actually Doing?

This project is a **professionally designed AI system** with a clean separation between **core logic**, **human-facing UI**, and **agent-facing APIs**.

At a high level, you built **ONE system with TWO entry points**:

* ðŸ§‘â€ðŸ’» **A normal user application (Streamlit)**
* ðŸ¤– **An AI-agent tool server (MCP)**

Both entry points **share the same core engine**, but they are meant for **different consumers**.

---

## ðŸ§  Big Picture Architecture

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ job_api.py â”‚  â† core business logic
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–²
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit  â”‚             â”‚ MCP Server   â”‚
â”‚  app.py    â”‚             â”‚ mcp_server.pyâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                           â”‚
       â–¼                           â–¼
    End User                AI / Agent
```

**Key idea:**

> The core logic does not care *who* is calling it â€” a human or an AI agent.

---

## ðŸ§± Step 0: Core Business Logic (The Foundation)

Before UI, before MCP, ask one question:

> **Where is the real work happening?**

### âœ… Answer

```
src/
 â”œâ”€â”€ job_api.py
 â””â”€â”€ helper.py
```

These two files are the **engine of the entire system**.

Everything else is just an **interface** on top.

---

## ðŸ”¹ job_api.py â€” â€œGet Me Real Jobsâ€

### What this file does

* Connects to **Apify**
* Fetches **real job listings** from:

  * LinkedIn
  * Naukri
* Returns **structured JSON data**

### Example

**Input**

```
"data scientist python"
```

**Output**

```json
[
  {
    "title": "Data Scientist",
    "company": "ABC Corp",
    "location": "Bangalore",
    "link": "https://..."
  }
]
```

### What it does NOT care about

* âŒ Streamlit
* âŒ MCP
* âŒ LLMs

This makes it **fully reusable** anywhere.

---

## ðŸ”¹ helper.py â€” â€œTalk to LLMs & Read PDFsâ€

### What this file does

* Extracts text from **resume PDFs** (PyMuPDF)
* Talks to **Groq LLM**
* Returns **plain text responses**

### Responsibilities

* Resume text extraction
* Resume summarization
* Skill gap analysis
* Career roadmap generation
* Keyword extraction for job search

### What it does NOT contain

* âŒ Streamlit UI code
* âŒ MCP logic

Just **pure utilities**.

---

## âœ… These Two Files = Your Engine

Everything else:

* UI
* APIs
* Agents

are just **different ways of using the same engine**.

---

## ðŸ§± Step 1: Streamlit App (Human Interface)

This is the part **users actually see**.

### How it runs

```
streamlit run app.py
```

ðŸ“Œ Important:

> When Streamlit runs, **MCP does NOT run**.

---

## ðŸ”¹ Step 1.1: Resume Upload

```python
uploaded_file = st.file_uploader(...)
```

User uploads a **PDF resume**.

---

## ðŸ”¹ Step 1.2: Resume Text Extraction

```python
resume_text = extract_text_from_pdf(uploaded_file)
```

**Flow**

```
PDF â†’ PyMuPDF â†’ Raw Text
```

---

## ðŸ”¹ Step 1.3: Resume Summarization (LLM)

```python
summary = ask_groq("Summarize this resume...")
```

**Flow**

```
Resume Text â†’ Groq LLM â†’ Summary
```

---

## ðŸ”¹ Step 1.4: Skill Gap Analysis (LLM)

```python
gaps = ask_groq("Highlight missing skills...")
```

**Flow**

```
Resume Text â†’ Groq LLM â†’ Missing Skills
```

---

## ðŸ”¹ Step 1.5: Career Roadmap (LLM)

```python
roadmap = ask_groq("Suggest future roadmap...")
```

**Flow**

```
Resume Text â†’ Groq LLM â†’ Career Plan
```

---

## ðŸ”¹ Step 1.6: Job Recommendation Button

Nothing happens automatically.

ðŸ‘‰ **Jobs are fetched ONLY when the user clicks the button**.

---

### Step 1.6.1: Extract Job Keywords (LLM)

```python
keywords = ask_groq("Suggest job titles & keywords...")
```

**Example Output**

```
Data Scientist, Machine Learning Engineer, Python, NLP
```

---

### Step 1.6.2: Fetch Jobs

```python
linkedin_jobs = fetch_linkedin_jobs(keywords)
naukri_jobs = fetch_naukri_jobs(keywords)
```

**Flow**

```
Keywords â†’ Apify â†’ LinkedIn + Naukri â†’ Jobs
```

---

### Step 1.6.3: Display Jobs

Streamlit loops through the results and renders **job cards** in the UI.

---

## âœ… This Is the Full Streamlit Flow

End-to-end, nothing hidden.

---

## ðŸ§± Step 2: MCP Server (Agent Interface)

This is where most confusion happens.

### â“ Is MCP running when Streamlit runs?

âŒ **NO**

They are completely independent.

---

## ðŸ”¹ What Is mcp_server.py?

It is a **separate program**.

### How it runs

```
python mcp_server.py
```

---

## ðŸ”¹ What Happens When MCP Runs?

* Starts an **MCP tool server**
* Registers tools:

  * `fetchlinkedin`
  * `fetchnaukri`
* Waits for an MCP client

Thatâ€™s it.

---

## âŒ What MCP Server Does NOT Do

* âŒ No UI
* âŒ No resume analysis
* âŒ No LLM calls
* âŒ No automatic job fetching

It just **exposes tools**.

---

## ðŸ§± Step 3: Who Calls the MCP Server?

### Right now?

ðŸ‘‰ **Nobody**.

You do **not** have an MCP client yet.

---

## ðŸ”® Possible Future MCP Clients

| Client                 | Role                |
| ---------------------- | ------------------- |
| Claude Desktop         | Calls tools via MCP |
| LangGraph Agent        | Uses MCP tools      |
| Custom `mcp_client.py` | Manual tool calls   |

---

## ðŸ” Example Future MCP Flow

```
Claude: "Find jobs for data scientist"
   â†“
Claude MCP Client
   â†“
mcp_server.py
   â†“
fetchlinkedin()
   â†“
Apify
```

---

## ðŸ§  Why Adding MCP Was a Smart Move

You accidentally did something **very professional**.

You separated:

* âœ… Business logic
* âœ… User interface
* âœ… Agent interface

This is **exactly** how real AI platforms are built.

---

## ðŸŽ¯ Final Mental Model (Memorize This)

* **Streamlit app** â†’ for humans
* **MCP server** â†’ for AI agents
* **Core logic** â†’ shared by both

ðŸ“Œ **Right now:**

> Only Streamlit is actively being used.

---

## ðŸ One-Line Summary

> **Streamlit app is for humans. MCP server is for AI agents. Core logic powers both.**

---

âœ¨ You didnâ€™t just build a project â€” you built a **scalable AI system architecture**.
